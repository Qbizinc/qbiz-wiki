<!--
title: GCP Professional Machine Learning Engineer
description: 
published: true
date: 2023-03-15T19:22:31.921Z
tags: 
editor: ckeditor
dateCreated: 2023-01-18T19:37:50.189Z
-->

<h1>GCP Professional Machine Learning Engineer</h1>
<h2>How to get access to the material?</h2>
<p>With QBiz, we're using GCP partner portal to access all the GCP trainings. To be able to register to <strong>Certification Learning Path: Professional Machine Learning Engineer </strong>you need to follow<strong> </strong>the path:</p>
<ol>
  <li>Ask Mayra Madrigal to send you GCP partner portal link.</li>
  <li>You'll receive an email with the title <strong>Welcome to Google Cloud Partner Advantage! </strong>Follow the “Login to the portal” link in the email, and login with your QBiz credentials.</li>
  <li>Under the tab “Training” you can see a list of Google Cloud certifications portfolio trainings, one of them being <strong>Professional Machine Learning Engineer. </strong>At least for me, the access was denied for all the certification trainings at this point.</li>
  <li>To get access to Machine Learning training, you need to follow the instructions in<a href="https://qbiz-wiki.com/en/training/Certifications/Google/Kickstart"> https://qbiz-wiki.com/en/training/Certifications/Google/Kickstart</a> . You'll notice there is no option for Machine Leaning in the Partner Certification Kickstart tab, so you can register for Professional Data Engineer training. It goes against intuition, but following this process, the Machine Learning trainings became accessible.</li>
</ol>
<h2>Estimated duration of the training is 40 days</h2>
<p>There is no easy way to see the estimated duration of all of the trainings in the GCP portal, you'll need to click each of the courses to see the estimated time of each part. That's why I outline the time estimates here:</p>
<ul>
  <li>Big Data and ML Fundamentals (1 day)</li>
  <li>How Google does Machine Learning 1 day)</li>
  <li>Launching into Machine Learning 4 days)</li>
  <li>TensorFlow on Google Cloud (3 days)</li>
  <li>Feature Engineering (3 days)</li>
  <li>Machine Learning in the Enterprise (4 days)</li>
  <li>Production Machine Learning Systems (2 days)</li>
  <li>Computer Vision Fundamentals with Google Cloud (GCP: No estimate. My rough estimate is 5 days)</li>
  <li>Sequence Models for Time Series and Natural Language Processing (1 day)</li>
  <li>Recommendation Systems with TensorFlow on Google Cloud (GCP estimate is 1 day, but it might not be accurate, as labs alone seem to take 9 h)</li>
  <li>MLOps (Machine Learning Operations) Fundamentals (5 days)</li>
  <li>ML Pipelines on Google Cloud, (GCP: No estimate. My rough estimate is 3 days)</li>
  <li>Perform Foundational Data, ML, AI Tasks in Google Cloud (1 day)</li>
  <li>Build and Deploy Machine Learning Solutions on Vertex AI (1 day)</li>
  <li>Preparing for the Professional Machine Learning Engineer Examination (GCP: No estimate. My rough estimate is 5 days)</li>
</ul>
<p><strong>Total 40 days</strong></p>
<p>Below I share a link to a Google sheet tool I made to quickly estimate the time you've left in the program and the likely date for finishing the training, based on the time estimates of each course:</p>
<p><a href="https://docs.google.com/spreadsheets/d/1t7T9vL-H_ZUU0kbYCK3crnAUZeg5C7rjAGg_IEw3kpY/edit#gid=0">https://docs.google.com/spreadsheets/d/1t7T9vL-H_ZUU0kbYCK3crnAUZeg5C7rjAGg_IEw3kpY/edit#gid=0</a></p>
<h2>Issues with Labs</h2>
<p>This section lists issues encountered in the Qwiklab labs in the course and provides solutions or workarounds where possible.</p>
<p>&nbsp;</p>
<h3>Introduction to Vertex Pipelines</h3>
<p>Problem:<br>One of the pipeline containers fails with the error <code>TypeError: emojize() got an unexpected keyword argument 'use_aliases' </code>.</p>
<p>Solution:<br>Simply remove the <code>use_aliases</code> parameter from the <code>emojize()</code> function call in the emoji component.</p>
<p>&nbsp;</p>
<h3>Structured data prediction using Vertex AI Platform</h3>
<p>It isn't that much of a problem, since the prompts are there in the notebook, but this lab uses the old AI Platform rather than Vertex AI in places (despite the title), so you need to enable the AI Platform API (ml.googleapis.com) as well as the standard Vertex AI APIs, and then the model &amp; jobs are listed in the AI Platform web UI rather than the conventional Vertex AI location. E.g. https://console.cloud.google.com/ai-platform/jobs</p>
<p>&nbsp;</p>
<h3>Keras for Text Classification using Vertex AI</h3>
<p>Problem: <code>model.fit()</code> only runs for two epochs, resulting in poor accuracy and there being insufficient data to graph in the subsequent metric curve plots.<br>Solution: The early stopping control parameter <code>patience </code>is set to zero, so the training gives up immediately. Set the <code>PATIENCE </code>constant to a small number greater than zero.</p>
<p>&nbsp;</p>
<h3>NLP on Google Cloud, Lab 1: Exploring the Dialogflow API</h3>
<p>In Task 1, you should open DialogFlow via link: <a href="https://partner.cloudskillsboost.google/course_sessions/2413062/labs/dialogflow.cloud.google.com">dialogflow.cloud.google.com,</a> but you'll encounter a “Page not found” error. Following link should work: &nbsp;<a href="https://dialogflow.cloud.google.com/#/getStarted">https://dialogflow.cloud.google.com/#/getStarted</a></p>
<p>&nbsp;</p>
<h3>ML on GCP: Hybrid Recommendations with the MovieLens Dataset</h3>
<p>The instructions at the start of the lab regarding running a “previous” lab are a bit vague and misleading. Enter the correct project ID then run all of the code cells in als_bqml.ipynb from the solutions folder to import the data to the BQ dataset.</p>
<p>&nbsp;</p>
<h3>Applying Contextual Bandits for Recommendation systems using Tensorflow and Cloud Storage</h3>
<p>I encountered a number of package dependency and permissions issues.&nbsp;</p>
<p>My hacky workaround:</p>
<p>Add the <code>--user</code> option to the two <code>pip install</code>s, then ignore all of the pip warnings and errors.</p>
<p>Execute &nbsp;</p>
<p><code>!sudo rm -f /opt/conda/lib/python3.7/site-packages/tensorflow/core/kernels/libtfkernel_sobol_op.so</code></p>
<p>before the code cell with the main imports.</p>
<p>There are also lots of variables set to None or 0 that need to be populated as indicated in the markup text, but without <code>TODO</code>s.&nbsp;</p>
<p>&nbsp;</p>
<h3>Build and Deploy Machine Learning Solutions with Vertex AI: Challenge Lab</h3>
<p>The instructions specify to keep the defaults when creating a Jupyter notebook and there was a pre-existing storage bucket with the correct name. However, for me, they were in different regions, which doesn't work. I don't know if you need to keep the default notebook region (probably not) but creating a bucket in the same region as the notebook worked for me.</p>
<p>&nbsp;</p>
<h3>TFX on Cloud AI Platform Pipelines</h3>
<p>TIP: Don't leave a trailing forward slash on the <code>ARTIFACT_STORE_URI</code> string, as it will cause the last stage of the Kubeflow pipeline to fail.</p>
<p>&nbsp;</p>
